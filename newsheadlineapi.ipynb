{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8036227,"sourceType":"datasetVersion","datasetId":4737418},{"sourceId":8175589,"sourceType":"datasetVersion","datasetId":4839372},{"sourceId":8252776,"sourceType":"datasetVersion","datasetId":4897055},{"sourceId":8265446,"sourceType":"datasetVersion","datasetId":4906560},{"sourceId":8266541,"sourceType":"datasetVersion","datasetId":4907428}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-30T12:14:35.095835Z","iopub.execute_input":"2024-04-30T12:14:35.096188Z","iopub.status.idle":"2024-04-30T12:14:36.053827Z","shell.execute_reply.started":"2024-04-30T12:14:35.096157Z","shell.execute_reply":"2024-04-30T12:14:36.052723Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/news-2-0/news_2.0.csv\n/kaggle/input/model-till-12000/config.json\n/kaggle/input/model-till-12000/model.safetensors\n/kaggle/input/model-till-12000/generation_config.json\n/kaggle/input/model-till-25000/config.json\n/kaggle/input/model-till-25000/merges.txt\n/kaggle/input/model-till-25000/vocab.json\n/kaggle/input/model-till-25000/tokenizer_config.json\n/kaggle/input/model-till-25000/model.safetensors\n/kaggle/input/model-till-25000/special_tokens_map.json\n/kaggle/input/model-till-25000/added_tokens.json\n/kaggle/input/model-till-25000/generation_config.json\n/kaggle/input/t5-finetuned/config.json\n/kaggle/input/t5-finetuned/spiece.model\n/kaggle/input/t5-finetuned/tokenizer_config.json\n/kaggle/input/t5-finetuned/model.safetensors\n/kaggle/input/t5-finetuned/special_tokens_map.json\n/kaggle/input/t5-finetuned/added_tokens.json\n/kaggle/input/t5-finetuned/generation_config.json\n/kaggle/input/model-till-32000/config.json\n/kaggle/input/model-till-32000/merges.txt\n/kaggle/input/model-till-32000/vocab.json\n/kaggle/input/model-till-32000/tokenizer_config.json\n/kaggle/input/model-till-32000/model.safetensors\n/kaggle/input/model-till-32000/special_tokens_map.json\n/kaggle/input/model-till-32000/added_tokens.json\n/kaggle/input/model-till-32000/generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\n\nimport matplotlib.pyplot as plt\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nfrom tqdm import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\nimport torch.optim as optim\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:14:36.055549Z","iopub.execute_input":"2024-04-30T12:14:36.056037Z","iopub.status.idle":"2024-04-30T12:14:53.327770Z","shell.execute_reply.started":"2024-04-30T12:14:36.056008Z","shell.execute_reply":"2024-04-30T12:14:53.326776Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-30 12:14:43.025008: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-30 12:14:43.025119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-30 12:14:43.156061: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge\n!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:16:08.464534Z","iopub.execute_input":"2024-04-30T12:16:08.464905Z","iopub.status.idle":"2024-04-30T12:16:33.670458Z","shell.execute_reply.started":"2024-04-30T12:16:08.464875Z","shell.execute_reply":"2024-04-30T12:16:33.669327Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nfrom rouge import Rouge\nrouge = Rouge()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:16:38.164323Z","iopub.execute_input":"2024-04-30T12:16:38.164708Z","iopub.status.idle":"2024-04-30T12:16:38.616493Z","shell.execute_reply.started":"2024-04-30T12:16:38.164675Z","shell.execute_reply":"2024-04-30T12:16:38.615582Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv(\"/kaggle/input/news-2-0/news_2.0.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:16:39.700952Z","iopub.execute_input":"2024-04-30T12:16:39.702030Z","iopub.status.idle":"2024-04-30T12:16:39.706482Z","shell.execute_reply.started":"2024-04-30T12:16:39.701997Z","shell.execute_reply":"2024-04-30T12:16:39.705329Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nimport torch\nfrom transformers import pipeline\n\nmodel_ckpt = \"facebook/bart-large-cnn\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\npipe = pipeline('summarization', model=model_ckpt, device = device)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:16:40.015594Z","iopub.execute_input":"2024-04-30T12:16:40.015984Z","iopub.status.idle":"2024-04-30T12:17:26.649895Z","shell.execute_reply.started":"2024-04-30T12:16:40.015952Z","shell.execute_reply":"2024-04-30T12:17:26.648864Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7f37c71c9b4851bb66215c63b08e26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df96e0b5c3a54515beb1c342124677e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"591be39515b143f880f18d1c0ace0a88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6c301c6b6f14f89bae26588fce3f85e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"406c7dc1ea1042d5a1bd5a4179339479"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd9793504f5647a89df42ffdf833d371"}},"metadata":{}}]},{"cell_type":"code","source":"# Example function to generate segments of text within the maximum sequence length\ndef generate_segments(input_text):\n    words = input_text.split()\n    for i in range(0, len(words), 300):  # Adjust the segment length here\n        yield ' '.join(words[i:i+300])   # Adjust the segment length here\n\ndef summarization(input_text):\n    global count\n    if(len(tokenizer.tokenize(input_text))<=510):\n        count += 1\n        print(count, end=\" \")\n        return input_text\n\n    output_summary = \"\"\n    for segment in generate_segments(input_text):\n        try:\n            max_length = len(segment.split()) # Adjust max_length dynamically\n            summarized_segment = pipe(segment, max_length=max_length, min_length=1, do_sample=False)[0]['summary_text']\n            output_summary += summarized_segment\n            \n        except IndexError:\n            pass\n        except Exception as e:\n            print(f\"Error occurred: {e}\")\n    if len(output_summary.split()) >= 510:\n            output_summary = summarization(output_summary)\n    count += 1\n    print(count, end=\" \")\n    return output_summary\ncount = 0","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:17:27.834605Z","iopub.execute_input":"2024-04-30T12:17:27.834967Z","iopub.status.idle":"2024-04-30T12:17:27.848758Z","shell.execute_reply.started":"2024-04-30T12:17:27.834938Z","shell.execute_reply":"2024-04-30T12:17:27.847741Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\n\nmodel_path = \"/kaggle/input/model-till-25000\"\n\n# Load the model\ntokenizer_gpt = GPT2Tokenizer.from_pretrained(model_path)\n# tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})\nmodel_gpt = GPT2LMHeadModel.from_pretrained(model_path)\n\n# If GPU is available, move the model to GPU\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_gpt.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:17:28.451874Z","iopub.execute_input":"2024-04-30T12:17:28.452575Z","iopub.status.idle":"2024-04-30T12:17:37.228743Z","shell.execute_reply.started":"2024-04-30T12:17:28.452539Z","shell.execute_reply":"2024-04-30T12:17:37.227776Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50258, 1024)\n    (wpe): Embedding(1024, 1024)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-23): 24 x GPT2Block(\n        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1024, out_features=50258, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\nmodel_path = \"/kaggle/input/t5-finetuned\"\nmodel_t5 = T5ForConditionalGeneration.from_pretrained(model_path)\ntokenizer_t5 = T5Tokenizer.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:17:41.868089Z","iopub.execute_input":"2024-04-30T12:17:41.868473Z","iopub.status.idle":"2024-04-30T12:17:48.899475Z","shell.execute_reply.started":"2024-04-30T12:17:41.868414Z","shell.execute_reply":"2024-04-30T12:17:48.898562Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install flask-ngrok >> /dev/null\n!pip install flask_cors\n!pip install pyngrok\nfrom flask import Flask,request,jsonify\nfrom pyngrok import ngrok\nfrom flask_cors import CORS\nfrom flask import Response\n!ngrok config add-authtoken 2cDjv295789xMxfOXzNy20lFY2C_2zrPAEF32U1teXtTXx2rr\nngrok.set_auth_token(\"2cDjv295789xMxfOXzNy20lFY2C_2zrPAEF32U1teXtTXx2rr\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:17:52.004613Z","iopub.execute_input":"2024-04-30T12:17:52.004975Z","iopub.status.idle":"2024-04-30T12:18:33.574174Z","shell.execute_reply.started":"2024-04-30T12:17:52.004950Z","shell.execute_reply":"2024-04-30T12:18:33.573139Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Collecting flask_cors\n  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: Flask>=0.9 in /opt/conda/lib/python3.10/site-packages (from flask_cors) (3.0.3)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (3.0.2)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (3.1.2)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (1.7.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (2.1.3)\nDownloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\nInstalling collected packages: flask_cors\nSuccessfully installed flask_cors-4.0.0\nCollecting pyngrok\n  Downloading pyngrok-7.1.6-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.1)\nDownloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.1.6\nAuthtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n","output_type":"stream"}]},{"cell_type":"code","source":"def summarize_text(text, model, max_new_tokens, max_length=512, num_beams=5):\n    inputs = tokenizer_t5(\n        \"summarize\" + text,\n        return_tensors='pt',\n        max_length=max_length,\n        truncation=True\n    )\n    \n    summary_ids = model.generate(\n        input_ids = inputs[\"input_ids\"],\n        attention_mask = inputs[\"attention_mask\"],\n        length_penalty=0.8,\n        do_sample = True,\n        max_new_tokens=max_new_tokens,\n        num_beams=num_beams\n    )\n    \n    return tokenizer_t5.decode(summary_ids[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:18:35.633404Z","iopub.execute_input":"2024-04-30T12:18:35.635260Z","iopub.status.idle":"2024-04-30T12:18:35.641769Z","shell.execute_reply.started":"2024-04-30T12:18:35.635221Z","shell.execute_reply":"2024-04-30T12:18:35.640665Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def generation_t5(query):\n#     rouge_scores = []\n    headline_t5 = []\n    # Generate 7 different outputs\n    num_outputs = 7\n    generated_outputs = []\n    max_new_tokens = 24\n    for _ in range(num_outputs):\n        output = summarize_text(query,model_t5,max_new_tokens+_)\n        headline_t5.append(output)\n#         scores = compute_metrics(output)\n#         rouge_scores.append(scores)\n#     print(rouge_scores)\n    return headline_t5\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:20:25.303608Z","iopub.execute_input":"2024-04-30T12:20:25.304468Z","iopub.status.idle":"2024-04-30T12:20:25.309915Z","shell.execute_reply.started":"2024-04-30T12:20:25.304426Z","shell.execute_reply":"2024-04-30T12:20:25.308868Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"reference_summary = '''Indian Football Witnesses 138% Growth In Women’s Player Registration In Last Two Years'''","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:20:26.314160Z","iopub.execute_input":"2024-04-30T12:20:26.314530Z","iopub.status.idle":"2024-04-30T12:20:26.318972Z","shell.execute_reply.started":"2024-04-30T12:20:26.314503Z","shell.execute_reply":"2024-04-30T12:20:26.317940Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def generation_gpt(query):\n    headline_gpt = []\n#     rouge_scores = []\n    try:\n#         print(query)\n        input_ids = tokenizer_gpt(query, return_tensors='pt')\n        # Move the input to GPU if available\n        input_ids = input_ids.to(\"cuda\")\n\n        num_outputs = 7\n        generated_outputs = []\n        max_new_tokens = 20\n        for _ in range(num_outputs):\n            # Generate output using the model\n            output = model_gpt.generate(\n                input_ids=input_ids[\"input_ids\"],\n                attention_mask=input_ids['attention_mask'],\n                length_penalty=0.8,\n                max_new_tokens=max_new_tokens + _,\n                num_beams=5,\n                no_repeat_ngram_size=2,\n                do_sample=True,\n                early_stopping=True\n            )\n            generated_outputs.append(tokenizer_gpt.decode(output[0], skip_special_tokens=True))\n\n        for output_text in generated_outputs:\n            # Find the index of \"TL;DR:\"\n            tldr_index = output_text.find(\"TL;DR:\")\n            if tldr_index != -1:\n                # Extract the text after \"TL;DR:\"\n                output_text = output_text[tldr_index + len(\"TL;DR:\"):]\n\n            # Remove commas and extra whitespaces from the output text\n            output_text = output_text.replace(\",\", \"\").strip()\n\n            headline_gpt.append(output_text)\n#             scores = compute_metrics(output_text)\n#             rouge_scores.append(scores)\n#         print(rouge_scores)\n    except Exception as e:\n        # Handle exceptions gracefully\n        print(\"An error occurred during headline generation:\", str(e))\n\n    return headline_gpt\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:20:26.729345Z","iopub.execute_input":"2024-04-30T12:20:26.730280Z","iopub.status.idle":"2024-04-30T12:20:26.739198Z","shell.execute_reply.started":"2024-04-30T12:20:26.730234Z","shell.execute_reply":"2024-04-30T12:20:26.738294Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Calculating ROUGE score for evaluation","metadata":{}},{"cell_type":"code","source":"app = Flask(__name__)\nCORS(app)\n\n@app.before_request\ndef basic_authentication():\n    if request.method.lower() == 'options':\n        return Response()\n\n\n@app.route(\"/\")\ndef home():\n    return jsonify({'result': \"result\"})\n\n@app.route('/api/t5data/',methods=['POST'])\ndef get_t5_data():\n    article = request.get_json()\n    sentence = summarization(article)\n    query = sentence \n    result = generation_t5(query)\n    return result\n\n@app.route('/api/gptdata/',methods=['POST'])\ndef get_gpt_data():\n    article = request.get_json()\n    sentence = summarization(article)\n    query = sentence + '\\nTL;DR:'\n    result = generation_gpt(query)\n    return result\n\nngrok_tunnel = ngrok.connect(5000)\nprint(' * Tunnel URL:', ngrok_tunnel.public_url)\n\nif __name__ == \"__main__\":\n    app.run()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:20:28.259765Z","iopub.execute_input":"2024-04-30T12:20:28.260135Z","iopub.status.idle":"2024-04-30T13:15:09.630625Z","shell.execute_reply.started":"2024-04-30T12:20:28.260107Z","shell.execute_reply":"2024-04-30T13:15:09.629643Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":" * Tunnel URL: https://0167-35-229-157-150.ngrok-free.app\n * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"2 ","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"3 ","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"4 ","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"5 ","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"6 ","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}