{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8264773,"sourceType":"datasetVersion","datasetId":4906044},{"sourceId":8266541,"sourceType":"datasetVersion","datasetId":4907428}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-29T18:12:46.779726Z","iopub.execute_input":"2024-04-29T18:12:46.780088Z","iopub.status.idle":"2024-04-29T18:12:47.669078Z","shell.execute_reply.started":"2024-04-29T18:12:46.780055Z","shell.execute_reply":"2024-04-29T18:12:47.667986Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/news-summarization/news_summary.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Installing required Libraries","metadata":{}},{"cell_type":"code","source":"!pip install tensorboard\n!pip install sentencepiece\n!pip install evaluate\n!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:12:47.671022Z","iopub.execute_input":"2024-04-29T18:12:47.671524Z","iopub.status.idle":"2024-04-29T18:13:40.334952Z","shell.execute_reply.started":"2024-04-29T18:12:47.671469Z","shell.execute_reply":"2024-04-29T18:13:40.333731Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.31.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a269dc2301d10b06cc25ffdbd40cb93eac7505ce0d0601cc3ad24656b4415a8d\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Importing Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport pprint\nimport evaluate\n\nfrom transformers import (\n    T5Tokenizer,\n    T5ForConditionalGeneration,\n    TrainingArguments,\n    Trainer\n)\n\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:13:40.336543Z","iopub.execute_input":"2024-04-29T18:13:40.336895Z","iopub.status.idle":"2024-04-29T18:13:57.076062Z","shell.execute_reply.started":"2024-04-29T18:13:40.336860Z","shell.execute_reply":"2024-04-29T18:13:57.075234Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-04-29 18:13:47.358268: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-29 18:13:47.358373: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-29 18:13:47.489971: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pp = pprint.PrettyPrinter()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:13:57.077991Z","iopub.execute_input":"2024-04-29T18:13:57.078739Z","iopub.status.idle":"2024-04-29T18:13:57.083059Z","shell.execute_reply.started":"2024-04-29T18:13:57.078707Z","shell.execute_reply":"2024-04-29T18:13:57.082123Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Importing Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/news-summarization/news_summary.csv\", encoding='latin1')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:13:57.084063Z","iopub.execute_input":"2024-04-29T18:13:57.084328Z","iopub.status.idle":"2024-04-29T18:13:57.530684Z","shell.execute_reply.started":"2024-04-29T18:13:57.084305Z","shell.execute_reply":"2024-04-29T18:13:57.529644Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2447125997.py:1: DtypeWarning: Columns (2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18,20,21,23,24,25,27,28,29,30,31,32,33,34,35,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,265,266,267,268,269,270,271,272,273,274,275,276) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/news-summarization/news_summary.csv\", encoding='latin1')\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df = df[[\"Summary\", \"Text\"]]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:13:57.532113Z","iopub.execute_input":"2024-04-29T18:13:57.532414Z","iopub.status.idle":"2024-04-29T18:13:57.562995Z","shell.execute_reply.started":"2024-04-29T18:13:57.532387Z","shell.execute_reply":"2024-04-29T18:13:57.562030Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:13:57.564125Z","iopub.execute_input":"2024-04-29T18:13:57.564404Z","iopub.status.idle":"2024-04-29T18:13:57.583143Z","shell.execute_reply.started":"2024-04-29T18:13:57.564381Z","shell.execute_reply":"2024-04-29T18:13:57.582260Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                Summary  \\\n0     The Daman and Diu administration on Wednesday ...   \n1     From her special numbers to TV?appearances, Bo...   \n2     Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n3     Hotels in Mumbai and other Indian cities are t...   \n4     An alleged suspect in a kidnapping case was fo...   \n...                                                 ...   \n4507  Mumbai, Feb 23 (PTI) Fruit juice concentrate m...   \n4508  Former cricketer Sachin Tendulkar was spotted ...   \n4509  Aamir Khan, whose last film Dangal told the st...   \n4510  Maharahstra Power Minister Chandrashekhar Bawa...   \n4511  More than half of the languages spoken by Indi...   \n\n                                                   Text  \n0     The Administration of Union Territory Daman an...  \n1     Malaika Arora slammed an Instagram user who tr...  \n2     Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n3     Hotels in Maharashtra will train their staff t...  \n4     A 32-year-old man on Wednesday was found hangi...  \n...                                                 ...  \n4507  Fruit juice concentrate maker Rasna is eyeing ...  \n4508  Former Indian cricketer Sachin Tendulkar atten...  \n4509  Aamir Khan, while talking about reality shows ...  \n4510  The Maharashtra government has initiated an in...  \n4511  At least 400 languages or more than half langu...  \n\n[4512 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Daman and Diu administration on Wednesday ...</td>\n      <td>The Administration of Union Territory Daman an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From her special numbers to TV?appearances, Bo...</td>\n      <td>Malaika Arora slammed an Instagram user who tr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hotels in Mumbai and other Indian cities are t...</td>\n      <td>Hotels in Maharashtra will train their staff t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>An alleged suspect in a kidnapping case was fo...</td>\n      <td>A 32-year-old man on Wednesday was found hangi...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4507</th>\n      <td>Mumbai, Feb 23 (PTI) Fruit juice concentrate m...</td>\n      <td>Fruit juice concentrate maker Rasna is eyeing ...</td>\n    </tr>\n    <tr>\n      <th>4508</th>\n      <td>Former cricketer Sachin Tendulkar was spotted ...</td>\n      <td>Former Indian cricketer Sachin Tendulkar atten...</td>\n    </tr>\n    <tr>\n      <th>4509</th>\n      <td>Aamir Khan, whose last film Dangal told the st...</td>\n      <td>Aamir Khan, while talking about reality shows ...</td>\n    </tr>\n    <tr>\n      <th>4510</th>\n      <td>Maharahstra Power Minister Chandrashekhar Bawa...</td>\n      <td>The Maharashtra government has initiated an in...</td>\n    </tr>\n    <tr>\n      <th>4511</th>\n      <td>More than half of the languages spoken by Indi...</td>\n      <td>At least 400 languages or more than half langu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>4512 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## T5 Data Prep with Training Data Column Names","metadata":{}},{"cell_type":"code","source":"df = df.rename(columns={\"Summary\":\"target_text\", \"Text\":\"source_text\"})\ndf = df[['source_text', 'target_text']]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.205560Z","iopub.execute_input":"2024-04-29T18:14:30.205874Z","iopub.status.idle":"2024-04-29T18:14:30.217874Z","shell.execute_reply.started":"2024-04-29T18:14:30.205843Z","shell.execute_reply":"2024-04-29T18:14:30.216843Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.222196Z","iopub.execute_input":"2024-04-29T18:14:30.222499Z","iopub.status.idle":"2024-04-29T18:14:30.243391Z","shell.execute_reply.started":"2024-04-29T18:14:30.222458Z","shell.execute_reply":"2024-04-29T18:14:30.242595Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4512 entries, 0 to 4511\nData columns (total 2 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   source_text  4511 non-null   object\n 1   target_text  4393 non-null   object\ndtypes: object(2)\nmemory usage: 70.6+ KB\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.244539Z","iopub.execute_input":"2024-04-29T18:14:30.244867Z","iopub.status.idle":"2024-04-29T18:14:30.254893Z","shell.execute_reply.started":"2024-04-29T18:14:30.244843Z","shell.execute_reply":"2024-04-29T18:14:30.253993Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df = df.astype({'source_text': str, 'target_text': str})\nprint(df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.256260Z","iopub.execute_input":"2024-04-29T18:14:30.256539Z","iopub.status.idle":"2024-04-29T18:14:30.265335Z","shell.execute_reply.started":"2024-04-29T18:14:30.256508Z","shell.execute_reply":"2024-04-29T18:14:30.264473Z"},"trusted":true},"outputs":[{"name":"stdout","text":"source_text    object\ntarget_text    object\ndtype: object\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.266380Z","iopub.execute_input":"2024-04-29T18:14:30.266724Z","iopub.status.idle":"2024-04-29T18:14:30.278598Z","shell.execute_reply.started":"2024-04-29T18:14:30.266695Z","shell.execute_reply":"2024-04-29T18:14:30.277701Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                         source_text  \\\n0  The Administration of Union Territory Daman an...   \n1  Malaika Arora slammed an Instagram user who tr...   \n2  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n3  Hotels in Maharashtra will train their staff t...   \n4  A 32-year-old man on Wednesday was found hangi...   \n\n                                         target_text  \n0  The Daman and Diu administration on Wednesday ...  \n1  From her special numbers to TV?appearances, Bo...  \n2  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n3  Hotels in Mumbai and other Indian cities are t...  \n4  An alleged suspect in a kidnapping case was fo...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_text</th>\n      <th>target_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Administration of Union Territory Daman an...</td>\n      <td>The Daman and Diu administration on Wednesday ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Malaika Arora slammed an Instagram user who tr...</td>\n      <td>From her special numbers to TV?appearances, Bo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hotels in Maharashtra will train their staff t...</td>\n      <td>Hotels in Mumbai and other Indian cities are t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A 32-year-old man on Wednesday was found hangi...</td>\n      <td>An alleged suspect in a kidnapping case was fo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom datasets import Dataset, load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.279730Z","iopub.execute_input":"2024-04-29T18:14:30.280005Z","iopub.status.idle":"2024-04-29T18:14:30.286431Z","shell.execute_reply.started":"2024-04-29T18:14:30.279980Z","shell.execute_reply":"2024-04-29T18:14:30.285635Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"full_dataset = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.287457Z","iopub.execute_input":"2024-04-29T18:14:30.287770Z","iopub.status.idle":"2024-04-29T18:14:30.396991Z","shell.execute_reply.started":"2024-04-29T18:14:30.287748Z","shell.execute_reply":"2024-04-29T18:14:30.396262Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"full_dataset = full_dataset.train_test_split(test_size=0.2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.398121Z","iopub.execute_input":"2024-04-29T18:14:30.398465Z","iopub.status.idle":"2024-04-29T18:14:30.419124Z","shell.execute_reply.started":"2024-04-29T18:14:30.398423Z","shell.execute_reply":"2024-04-29T18:14:30.418468Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"dataset_train = full_dataset['train']\ndataset_valid = full_dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.420011Z","iopub.execute_input":"2024-04-29T18:14:30.420251Z","iopub.status.idle":"2024-04-29T18:14:30.424370Z","shell.execute_reply.started":"2024-04-29T18:14:30.420230Z","shell.execute_reply":"2024-04-29T18:14:30.423397Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"print(dataset_train)\nprint(dataset_valid)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.425854Z","iopub.execute_input":"2024-04-29T18:14:30.426243Z","iopub.status.idle":"2024-04-29T18:14:30.435036Z","shell.execute_reply.started":"2024-04-29T18:14:30.426218Z","shell.execute_reply":"2024-04-29T18:14:30.434145Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['source_text', 'target_text', '__index_level_0__'],\n    num_rows: 3514\n})\nDataset({\n    features: ['source_text', 'target_text', '__index_level_0__'],\n    num_rows: 879\n})\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Using SimpleT5 for Model Training","metadata":{}},{"cell_type":"markdown","source":"### Configuration","metadata":{}},{"cell_type":"code","source":"MODEL = \"t5-base\"\nBATCH_SIZE = 4\nNUM_PROCS = 4\nEPOCHS = 10\nOUT_DIR =\"result_t5base\"\nMAX_LENGTH=512","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.436039Z","iopub.execute_input":"2024-04-29T18:14:30.436338Z","iopub.status.idle":"2024-04-29T18:14:30.443229Z","shell.execute_reply.started":"2024-04-29T18:14:30.436315Z","shell.execute_reply":"2024-04-29T18:14:30.442548Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.444431Z","iopub.execute_input":"2024-04-29T18:14:30.444759Z","iopub.status.idle":"2024-04-29T18:14:30.451409Z","shell.execute_reply.started":"2024-04-29T18:14:30.444723Z","shell.execute_reply":"2024-04-29T18:14:30.450709Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(MODEL)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:30.452436Z","iopub.execute_input":"2024-04-29T18:14:30.452723Z","iopub.status.idle":"2024-04-29T18:14:32.074353Z","shell.execute_reply.started":"2024-04-29T18:14:30.452701Z","shell.execute_reply":"2024-04-29T18:14:32.073434Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e60dfb055d1c429b86cda88e2593412b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd5507b5326c46419f767d701e814440"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"178afc97e3674095b8173155e58ece21"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [f\"summarize: {article}\" for article in examples[\"source_text\"]]\n    model_inputs = tokenizer(\n        inputs,\n        max_length=MAX_LENGTH,\n        truncation=True,\n        padding=\"max_length\"\n    )\n    \n    targets = [summary for summary in examples[\"target_text\"]]\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            targets,\n            max_length=MAX_LENGTH,\n            truncation=True,\n            padding=\"max_length\"\n        )\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n\ntokenizer_train = dataset_train.map(\n    preprocess_function,\n    batched=True,\n    num_proc=NUM_PROCS\n)\n\ntokenized_valid = dataset_valid.map(\n    preprocess_function,\n    batched=True,\n    num_proc=NUM_PROCS\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:32.075765Z","iopub.execute_input":"2024-04-29T18:14:32.076119Z","iopub.status.idle":"2024-04-29T18:14:40.231765Z","shell.execute_reply.started":"2024-04-29T18:14:32.076085Z","shell.execute_reply":"2024-04-29T18:14:40.230869Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/3514 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f76403695485431fafeef13cd166b220"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/879 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"320a2ba120074c859cdeb1a549e93ecf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(MODEL)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:40.233157Z","iopub.execute_input":"2024-04-29T18:14:40.233446Z","iopub.status.idle":"2024-04-29T18:14:44.512073Z","shell.execute_reply.started":"2024-04-29T18:14:40.233417Z","shell.execute_reply":"2024-04-29T18:14:44.511179Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14332de5893540e98bcd91428d3a8111"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7755ae2dcac44e6889e8538fd42804f7"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"### ROUGE Metric","metadata":{}},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:44.513174Z","iopub.execute_input":"2024-04-29T18:14:44.513464Z","iopub.status.idle":"2024-04-29T18:14:46.034824Z","shell.execute_reply.started":"2024-04-29T18:14:44.513438Z","shell.execute_reply":"2024-04-29T18:14:46.033900Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"586c7a147f41437d912f21642443869d"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred.predictions[0], eval_pred.label_ids\n    \n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)  # Corrected typo in variable name\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)  # Corrected typo in function name\n    \n    result = rouge.compute(\n        predictions=decoded_preds,\n        references=decoded_labels,\n        use_stemmer=True,\n        rouge_types=[\n            \"rouge1\",\n            \"rouge2\",\n            \"rougeL\"\n        ]\n    )\n    \n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    \n    result = {k: round(v, 4) for k, v in result.items()}  # Corrected syntax to assign to result variable\n    \n    return result  # Added return statement\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:46.036175Z","iopub.execute_input":"2024-04-29T18:14:46.036558Z","iopub.status.idle":"2024-04-29T18:14:46.043975Z","shell.execute_reply.started":"2024-04-29T18:14:46.036525Z","shell.execute_reply":"2024-04-29T18:14:46.042883Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def preprocess_logits_for_metrics(logits, labels):\n    \n    pred_ids = torch.argmax(logits[0], dim=-1)\n    return pred_ids, labels","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:14:46.045085Z","iopub.execute_input":"2024-04-29T18:14:46.045394Z","iopub.status.idle":"2024-04-29T18:14:46.060038Z","shell.execute_reply.started":"2024-04-29T18:14:46.045369Z","shell.execute_reply":"2024-04-29T18:14:46.059197Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=OUT_DIR,\n    num_train_epochs=EPOCHS,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_steps=50,\n    logging_dir=OUT_DIR,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    save_total_limit=2,\n    report_to=\"tensorboard\",\n    learning_rate=0.0001,\n    dataloader_num_workers=4\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenizer_train,\n    eval_dataset=tokenized_valid,\n    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:27:27.016526Z","iopub.execute_input":"2024-04-29T18:27:27.017530Z","iopub.status.idle":"2024-04-29T18:27:27.055645Z","shell.execute_reply.started":"2024-04-29T18:27:27.017495Z","shell.execute_reply":"2024-04-29T18:27:27.054787Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"history = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T18:27:28.337714Z","iopub.execute_input":"2024-04-29T18:27:28.338075Z","iopub.status.idle":"2024-04-29T20:49:11.204329Z","shell.execute_reply.started":"2024-04-29T18:27:28.338046Z","shell.execute_reply":"2024-04-29T20:49:11.203176Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8790' max='8790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8790/8790 2:21:41, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.364100</td>\n      <td>2.261965</td>\n      <td>0.522800</td>\n      <td>0.200600</td>\n      <td>0.398600</td>\n      <td>383.970400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.408600</td>\n      <td>2.194570</td>\n      <td>0.528800</td>\n      <td>0.204600</td>\n      <td>0.404200</td>\n      <td>383.927200</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.266400</td>\n      <td>2.165240</td>\n      <td>0.531600</td>\n      <td>0.206700</td>\n      <td>0.406500</td>\n      <td>383.874900</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.184200</td>\n      <td>2.151594</td>\n      <td>0.535700</td>\n      <td>0.208300</td>\n      <td>0.408800</td>\n      <td>383.912400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.128900</td>\n      <td>2.141923</td>\n      <td>0.536800</td>\n      <td>0.210100</td>\n      <td>0.410100</td>\n      <td>383.880500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.005700</td>\n      <td>2.136505</td>\n      <td>0.537400</td>\n      <td>0.210300</td>\n      <td>0.410700</td>\n      <td>383.889600</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.042200</td>\n      <td>2.134662</td>\n      <td>0.539800</td>\n      <td>0.211100</td>\n      <td>0.411600</td>\n      <td>383.897600</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.040700</td>\n      <td>2.130030</td>\n      <td>0.540100</td>\n      <td>0.211400</td>\n      <td>0.411800</td>\n      <td>383.866900</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.910900</td>\n      <td>2.130827</td>\n      <td>0.541000</td>\n      <td>0.211400</td>\n      <td>0.412000</td>\n      <td>383.879400</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.099700</td>\n      <td>2.131778</td>\n      <td>0.540700</td>\n      <td>0.211700</td>\n      <td>0.412100</td>\n      <td>383.886200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\nmodel_path = \"/kaggle/input/t5-finetuned\"\nmodel = T5ForConditionalGeneration.from_pretrained(model_path)\ntokenizer = T5Tokenizer.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T11:56:33.508097Z","iopub.execute_input":"2024-04-30T11:56:33.508489Z","iopub.status.idle":"2024-04-30T11:56:42.818319Z","shell.execute_reply.started":"2024-04-30T11:56:33.508458Z","shell.execute_reply":"2024-04-30T11:56:42.817469Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-04-30T11:59:29.200485Z","iopub.execute_input":"2024-04-30T11:59:29.201420Z","iopub.status.idle":"2024-04-30T11:59:41.257103Z","shell.execute_reply.started":"2024-04-30T11:59:29.201372Z","shell.execute_reply":"2024-04-30T11:59:41.256009Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"model.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:02:26.153995Z","iopub.execute_input":"2024-04-30T12:02:26.154677Z","iopub.status.idle":"2024-04-30T12:02:26.426311Z","shell.execute_reply.started":"2024-04-30T12:02:26.154642Z","shell.execute_reply":"2024-04-30T12:02:26.425435Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import torch\nfrom rouge import Rouge\n\n\n# Define the generated summary and the reference summary\nreference_summary = '''Indian Football Witnesses 138% Growth In Women’s Player Registration In Last Two Years'''\n\n# Initialize the ROUGE object\nrouge = Rouge()\n\n# Define the input text for GPT-2\ninput_text = '''Indian football has experienced a historic 138% surge in the registration of women players over the past two years, indicating a significant growth in the sport’s popularity and an increase in young female athletes pursuing football professionally.\n\nAccording to data from the All India Football Federation (AIFF) Central Registration System (CRS), India now boasts 27,936 registered female footballers as of March 2024, compared to 11,724 in June 2022.\n\nKalyan Chaubey, President of AIFF, credited this growth to various initiatives implemented during the current season, including the introduction of the Indian Women’s League (IWL-2) as a second-tier competition.\n\nThe 2022-23 season of the IWL took place in Ahmedabad, featuring 16 teams in a single venue, with Gokulam Kerala FC clinching their third consecutive title. In the following season (2023-24), the format shifted to a ‘home-and-away’ structure, receiving widespread praise from clubs, players, and fans. Odisha FC emerged victorious, ending Gokulam Kerala FC’s three-year dominance and earning the opportunity to represent India in AFC continental competition.\n\nThe inaugural IWL-2 witnessed the participation of 15 clubs in the group stage, with six advancing to the final round scheduled for the next month in Kolkata.\n\nIndia currently hosts 24 active State Leagues for women’s football, serving as the third tier of the pyramid and contributing to the sport’s widespread adoption across the country.\n\nChaubey said that over the past 16-18 months, they have taken incremental steps with a concentrated focus on women’s football. This current season marks a significant turning point for Indian football in multiple aspects.\n\nHe mentioned that they’re witnessing rapid growth in women’s football across India. Both players and clubs are benefiting from increased game time, driven by a rise in domestic matches, which has intensified competition. The prospect of participating in the AFC Women’s Cup, organized by the AFC, serves as a major incentive for Indian clubs today.\n\nLooking ahead, the AIFF President emphasised that women’s football will receive more priority in the coming years, ensuring sustained development and progress in the sport.''' + '\\nTL;DR:'\n\n# Tokenize input text\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n\n# Generate predictions\noutput = model.generate(\n        input_ids = input_ids[\"input_ids\"],\n        attention_mask = input_ids[\"attention_mask\"],\n        length_penalty=0.8,\n        do_sample = True,\n        max_new_tokens=30,\n        num_beams=8\n    )\n\n# Decode the generated sequence\noutput_text = tokenizer.decode(output[0], skip_special_tokens=True)\n\ngenerated_text = output_text","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:10:24.470914Z","iopub.execute_input":"2024-04-30T12:10:24.471317Z","iopub.status.idle":"2024-04-30T12:10:25.113154Z","shell.execute_reply.started":"2024-04-30T12:10:24.471285Z","shell.execute_reply":"2024-04-30T12:10:25.112397Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Calculate ROUGE for the generated and reference summaries\nscores = rouge.get_scores(generated_text[24:], reference_summary)\n# Print the results\nprint(scores)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:10:56.418138Z","iopub.execute_input":"2024-04-30T12:10:56.418849Z","iopub.status.idle":"2024-04-30T12:10:56.424295Z","shell.execute_reply.started":"2024-04-30T12:10:56.418823Z","shell.execute_reply":"2024-04-30T12:10:56.423204Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[{'rouge-1': {'r': 0.16666666666666666, 'p': 0.1111111111111111, 'f': 0.1333333285333335}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.16666666666666666, 'p': 0.1111111111111111, 'f': 0.1333333285333335}}]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"generated_text[24:]","metadata":{"execution":{"iopub.status.busy":"2024-04-30T12:11:15.360728Z","iopub.execute_input":"2024-04-30T12:11:15.361101Z","iopub.status.idle":"2024-04-30T12:11:15.370218Z","shell.execute_reply.started":"2024-04-30T12:11:15.361071Z","shell.execute_reply":"2024-04-30T12:11:15.369324Z"},"trusted":true},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'Indian football has experienced a historic 138% surge in the registration of women players over the past two years'"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"def summarize_text(text, model, max_length=512, num_beams=5):\n    inputs = tokenizer.encode(\n        \"summarize\" + text,\n        return_tensors='pt',\n        max_length=max_length,\n        truncation=True\n    )\n    \n    summary_ids = model.generate(\n        inputs,\n        max_length=24,\n        num_beams=num_beams\n    )\n    \n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:51:52.376942Z","iopub.execute_input":"2024-04-29T20:51:52.377354Z","iopub.status.idle":"2024-04-29T20:51:52.383752Z","shell.execute_reply.started":"2024-04-29T20:51:52.377320Z","shell.execute_reply":"2024-04-29T20:51:52.382577Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summarize_text()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Saving Model","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"T5_summarization\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:49:28.302850Z","iopub.execute_input":"2024-04-29T20:49:28.303547Z","iopub.status.idle":"2024-04-29T20:49:29.794632Z","shell.execute_reply.started":"2024-04-29T20:49:28.303506Z","shell.execute_reply":"2024-04-29T20:49:29.793554Z"},"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"tokenizer.save_pretrained(\"tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:49:32.701077Z","iopub.execute_input":"2024-04-29T20:49:32.702276Z","iopub.status.idle":"2024-04-29T20:49:32.713624Z","shell.execute_reply.started":"2024-04-29T20:49:32.702231Z","shell.execute_reply":"2024-04-29T20:49:32.712746Z"},"trusted":true},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/spiece.model',\n 'tokenizer/added_tokens.json')"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"from IPython.display import FileLink\n\nfile_path = \"T5_summarization/model.safetensors\"  # Specify the full path to the file\nlink = FileLink(file_path)\nlink\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:49:48.371993Z","iopub.execute_input":"2024-04-29T20:49:48.372673Z","iopub.status.idle":"2024-04-29T20:49:48.378986Z","shell.execute_reply.started":"2024-04-29T20:49:48.372643Z","shell.execute_reply":"2024-04-29T20:49:48.378051Z"},"trusted":true},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/T5_summarization/model.safetensors","text/html":"<a href='T5_summarization/model.safetensors' target='_blank'>T5_summarization/model.safetensors</a><br>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}